# PromptClass â€” Text-Guided Image Classification using Vision-Language Models (CLIP)

A web-based image classification system that uses **Zero-Shot Learning** with **OpenAI CLIP**.  
Users can upload an image, type a natural-language prompt such as:

This is an image of a {class_name}.


Add multiple class names and the system predicts the best-matching class using **cosine similarity** between image and text embeddings.

---

## ğŸš€ Features

### ğŸ” Zero-Shot Image Classification
No training required â€” CLIP understands relationships between text and images out of the box.

### ğŸ–¼ï¸ Interactive Web UI
- Upload any image  
- Add class names dynamically  
- Customize the prompt template  
- Classify instantly  
- View similarity scores for each class  

### âš™ï¸ FastAPI Backend
Handles:
- Image upload  
- Prompt construction  
- CLIP inference  
- Scoring & prediction  

### ğŸ¨ Fully Customizable
Change prompts, model, or UI easily.

---

## ğŸ§  How It Works

Frontend (HTML/CSS/JS)
â”‚ (image + class names + prompt)
â–¼
FastAPI Backend
â”‚
â–¼
CLIP Model (HuggingFace)
â”‚
â–¼
Cosine Similarity Scores
â”‚
â–¼
Predicted Class

---

## ğŸ“‚ Folder Structure

promptclass-app/
â”œâ”€â”€ backend/
â”‚ â”œâ”€â”€ main.py
â”‚ â””â”€â”€ model.py
â”œâ”€â”€ frontend/
â”‚ â”œâ”€â”€ index.html
â”‚ â”œâ”€â”€ styles.css
â”‚ â””â”€â”€ app.js
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

---

## ğŸ”§ Installation & Setup

### 1ï¸âƒ£ Clone the Repository

git clone https://github.com/anoynomous00/ImageClassification.git

cd ImageClassification/promptclass-app

2ï¸âƒ£ Create Virtual Environment

python -m venv .venv

3ï¸âƒ£ Activate It

Windows

.\.venv\Scripts\Activate.ps1

4ï¸âƒ£ Install Requirements

pip install -r requirements.txt

â–¶ï¸ Running the Project

Start Backend

uvicorn backend.main:app --reload --host 0.0.0.0 --port 8000

ğŸŒOpen UI in Browser

http://localhost:8000

#### ğŸ“¸ Example

Prompt template:
This is an image of a {class_name}.

Classes: cat, dog

Output:

cat â†’ 0.92
dog â†’ 0.13

Predicted: cat


### ğŸ§ª API Documentation
#### POST /api/classify

###### Field | Type	| Description

file | image | Upload an image file

classes	| JSON | e.g. ["cat","dog","car"]

template | string	| Must contain {class_name}

Response:

{

  "classes": {
  
    "cat": { "cosine": 0.92, "scaled": 0.96 },
    
    "dog": { "cosine": 0.13, "scaled": 0.56 }
    
  },
  
  "best_class": "cat",
  
  "best_prompt": "This is an image of a cat.",
  
  "best_score": { "cosine": 0.92, "scaled": 0.96 }
  
}

### ğŸ› ï¸ Technologies Used

Tech	Purpose

FastAPI	Backend API

HTML/CSS/JS	Frontend

HuggingFace Transformers	CLIP model

PyTorch	Inference

Uvicorn	ASGI Server

### ğŸ“¦ Deployment

You can deploy using:

Docker

Railway

Render

AWS EC2

Azure App Service

Heroku

(Dockerfile available on request)

### ğŸ§‘â€ğŸ’» Author
Amith Banakar - Developer

OpenAI CLIP Team â€” Vision-Language Model

### ğŸ“œ License
MIT License â€” free to use and modify.

---
